{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "apOCQivpbmo7",
        "outputId": "672ee41e-fbbb-46ed-9afc-aace06b2c8d1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-203ac8e1c8e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name !='/device:GPU:0':\n",
        "  raise SystemError(\"Gpu not\")\n",
        "print('Gpu found at {} '.format(device_name))"
      ],
      "metadata": {
        "id": "GO7_fzusbtj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "B0JRq2Zubtls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/Master/Fall 22/DS Project/Undersampled_dataset\n",
        "!ls"
      ],
      "metadata": {
        "id": "1LQYqkO2btnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_in = open(\"X_test.pickle\",\"rb\")\n",
        "X_test = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"X_train.pickle\",\"rb\")\n",
        "X_train = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"Y_test.pickle\",\"rb\")\n",
        "Y_test = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"Y_train.pickle\",\"rb\")\n",
        "Y_train = pickle.load(pickle_in)"
      ],
      "metadata": {
        "id": "Nqheh9q5btpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "image_size = 224\n",
        "IMG_SHAPE = (image_size, image_size, 3)\n",
        "y = np.array(Y_train)"
      ],
      "metadata": {
        "id": "K079r2Qhbtrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.applications import vgg16\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.optimizers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, GlobalAveragePooling2D,Dropout\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, EarlyStopping\n",
        "import keras.optimizers\n",
        "from sklearn.metrics import classification_report\n",
        "import keras.optimizers\n",
        "from keras.applications import mobilenet_v2\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "from keras import Model\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "8dzXqQVwbtt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotGraphs(history,fold_no,epochs):\n",
        "  %cd '/content/gdrive/MyDrive/Graphs/'\n",
        " #summarize history for accuracy\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title(f'{fold_no} model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.savefig(f'MobileNet_UfR_1-00_Undersampling_wThreshold_{epochs}epoch_{fold_no}fold_no_accuracyGraph.png')\n",
        "  plt.show()\n",
        "  #summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(f'{fold_no} model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.savefig(f'MobileNet_UfR_1-00_Undersampling_wThreshold_{epochs}epoch_{fold_no}fold_no_LossGraph.png')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "nQxD0F3RcS5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyThresholdCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, valLoss_threshold, valAccuracy_threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.valLoss_threshold = valLoss_threshold\n",
        "        self.valAccuracy_threshold = valAccuracy_threshold\n",
        "        \n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs[\"val_loss\"] \n",
        "        val_accuracy = logs[\"val_accuracy\"]\n",
        "        if (val_loss <= self.valLoss_threshold) and (val_accuracy >= self.valAccuracy_threshold):\n",
        "            #print(f'Total Epochs Completed: {logs[\"Epoch\"]}')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "my_callback = MyThresholdCallback(valLoss_threshold=1.0,valAccuracy_threshold=0.9)            "
      ],
      "metadata": {
        "id": "whbseiaqcS1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = X_train\n",
        "targets = y\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "num_folds = 5\n",
        "epochs = 500\n",
        "train = 100\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "  base_model = mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, input_shape=IMG_SHAPE)\n",
        "\n",
        "  CLASSES = 4\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True  # should be True\n",
        "\n",
        "  optm = optimizers.Adam(learning_rate=0.001)    \n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer= optm,\n",
        "              metrics=['accuracy']\n",
        "              )\n",
        "  \n",
        "  logs = f'/content/gdrive/MyDrive/Logs/MobileNet_Kfold/MobileNet_Undersampling_UfR_1-00_wThreshold_fold_no_{fold_no}/'\n",
        "\n",
        "  \n",
        "  history = model.fit(inputs, targets, batch_size=32, epochs=epochs, validation_split=0.25, callbacks= [my_callback],\n",
        "                          use_multiprocessing=True)\n",
        "  \n",
        "  plotGraphs(history,fold_no,epochs)\n",
        "  \n",
        "  %cd f'/content/gdrive/MyDrive/Logs/ExcelLogs/MobileNet_Undersampling_UfR_1-00_wThreshold_epochs_{epochs}/'\n",
        "  hist_df = pd.DataFrame(history.history)  \n",
        "  hist_csv_file = f'MobileNet_Undersampling_UfR_1-00_wThreshold_Kfold_history_fold_{fold_no}.csv'\n",
        "  with open(hist_csv_file, mode='w') as f:\n",
        "      hist_df.to_csv(f)\n",
        "\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  y_train_pred = model.predict(X_train, batch_size=64, verbose=1)\n",
        "  y_train_pred_bool = np.argmax(y_train_pred, axis=1)\n",
        "  print(f\"Classification report on Training data fold-{fold_no}:\")\n",
        "  print(classification_report(y, y_train_pred_bool))\n",
        "\n",
        "  y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
        "  y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "  print(f\"Classification report on Test data:-{fold_no}\")\n",
        "  print(classification_report(Y_test, y_pred_bool))\n",
        "\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Validation Loss: {loss_per_fold[i]} - Validation Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------') "
      ],
      "metadata": {
        "id": "gedZiZY7cSzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNi08bnabtvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVf85sejbtxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wXIHGs-bt3C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}