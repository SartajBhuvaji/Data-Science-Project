{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkRg_lkBPM_q",
        "outputId": "d0b50078-b7e5-4d14-bca5-324d582f6c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.python.profiler import profiler_client\n",
        "\n",
        "tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "print(profiler_client.monitor(tpu_profile_service_address, 100, 2))"
      ],
      "metadata": {
        "id": "rjd8MmLOPcgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = '/content/gdrive/MyDrive/Master/Fall 22/DS Project/CornDataSet/Testing/' # test data folder\n",
        "IMG_SIZE = 224 # image size\n",
        "CATEGORIES = [\"healthy\",\"common_rust\",\"gray_leaf_spot\",\"northern_leaf_blight\"]"
      ],
      "metadata": {
        "id": "9cfbm1XOPjb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pickle"
      ],
      "metadata": {
        "id": "4brNzFNNQAZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "\n",
        "def create_test_data():\n",
        "\n",
        "    for category in CATEGORIES: \n",
        "\n",
        "        path = os.path.join(TEST_DIR,category)  # create path \n",
        "        class_num = CATEGORIES.index(category)  # get the classification  \n",
        "\n",
        "        for img in tqdm(os.listdir(path)): \n",
        "          # iterate over each image per dogs and cats\n",
        "          img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)  # convert to array\n",
        "          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "          test_data.append([new_array, class_num])  # add this to our training_data\n",
        "            \n",
        "    random.shuffle(test_data)\n",
        "    #np.save('train_data1.npy', training_data)        \n",
        "\n",
        "create_test_data()\n",
        "#np.save('train_data.npy', training_data)   \n",
        "print(\"Test data size: \",len(test_data))\n",
        "\n",
        "#print(\"Test npm created.\")\n",
        "print()\n",
        "X_test = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "Y_test = [i[1] for i in test_data]\n",
        "\n",
        "pickle_out = open(\"X_test.pickle\",\"wb\")\n",
        "pickle.dump(X_test, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"Y_test.pickle\",\"wb\")\n",
        "pickle.dump(Y_test, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "print(\"Pickle saved.\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2wVz79HP6f5",
        "outputId": "26bdcb40-5aba-489d-aac7-983eb6e67492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [00:01<00:00, 206.88it/s]\n",
            "100%|██████████| 238/238 [00:01<00:00, 207.85it/s]\n",
            "100%|██████████| 103/103 [00:00<00:00, 197.46it/s]\n",
            "100%|██████████| 197/197 [00:00<00:00, 202.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data size:  772\n",
            "\n",
            "Pickle saved.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o05kwwUbUKfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3epLec5iUKhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6r7_ArLUKkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/MyDrive/Master/Fall 22/DS Project/'\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDDiHcucUKnQ",
        "outputId": "52840ae7-cc0b-4e48-eff0-4a2dc196d168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Master/Fall 22/DS Project\n",
            "'Colab Notebooks'   DataSet  'New Folder'   Testing\n",
            " CornDataSet\t    Files     Reports\t   'Training '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjGrsoLtUKqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/gdrive/MyDrive/Master/Fall 22/DS Project/CornDataSet/Training/' # test data folder\n",
        "IMG_SIZE = 224 # image size\n",
        "CATEGORIES = [\"healthy\",\"common_rust\",\"gray_leaf_spot\",\"northern_leaf_blight\"]"
      ],
      "metadata": {
        "id": "YkxxI10sRCun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sqt0-yTURvEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "#/content/gdrive/MyDrive/Master/Fall 22/DS Project/Training /healthy\n",
        "def create_training_data():\n",
        "\n",
        "    for category in CATEGORIES: \n",
        "\n",
        "        path = os.path.join(TRAIN_DIR,category)  # create path \n",
        "        class_num = CATEGORIES.index(category)  # get the classification  \n",
        "\n",
        "        for img in tqdm(os.listdir(path)): \n",
        "          # iterate over each image per dogs and cats\n",
        "          img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_COLOR)  # convert to array\n",
        "          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "          training_data.append([new_array, class_num])  # add this to our training_data\n",
        "            \n",
        "    random.shuffle(training_data)\n",
        "    #np.save('train_data1.npy', training_data)        \n",
        "\n",
        "create_training_data()\n",
        "#np.save('train_data.npy', training_data)   \n",
        "print(\"Test data size: \",len(training_data))\n",
        "\n",
        "#print(\"train\")\n",
        "print()\n",
        "X_train = np.array([i[0] for i in training_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
        "Y_train = [i[1] for i in training_data]\n",
        "\n",
        "pickle_out = open(\"X_train.pickle\",\"wb\")\n",
        "pickle.dump(X_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"Y_train.pickle\",\"wb\")\n",
        "pickle.dump(Y_train, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "print(\"Pickle saved.\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c2G06lTRvSv",
        "outputId": "dca7c7f8-071b-4dc4-eef3-ee1e594e44fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 928/928 [00:04<00:00, 187.02it/s]\n",
            "100%|██████████| 954/954 [00:05<00:00, 184.26it/s]\n",
            "100%|██████████| 410/410 [00:02<00:00, 196.69it/s]\n",
            "100%|██████████| 788/788 [00:04<00:00, 191.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data size:  3080\n",
            "\n",
            "Pickle saved.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ait1QiqMRvWM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}